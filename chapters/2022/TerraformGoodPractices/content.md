---
layout: default
title:  Les bonnes pratiques lors de l'utilisation de Terraform
date:   2022-01-10 18:25:00 +0100
---

**_janvier 2022_**

## Auteurs

Nous sommes cinq √©tudiants en derni√®re ann√©e √† Polytech Nice Sophia, en mineure Architectures Logicielles :

* Jo√£o Brilhante &#60;joao.brilhante@etu.unice.fr&#62;
* Enzo Briziarelli &#60;enzo.briziarelli@etu.unice.fr&#62;
* Charly Ducrocq &#60;charly.ducrocq@etu.unice.fr&#62;
* Quentin Larose &#60;quentin.larose@etu.unice.fr&#62;
* Ludovic Marti &#60;ludovic.marti@etu.unice.fr&#62;

## I. Pr√©sentation

Les technologies cloud sont en plein essor et sont utilis√©es dans de nombreux projets r√©put√©s. Permettre un d√©ploiement automatique et configurable de ces environnements est indispensable pour ces projets. En ce sens, des technologies, permettant une automatisation du d√©ploiement de ces syst√®mes sur des infrastructures cloud et d‚Äôen configurer plusieurs aspects (ex. cloud provider, ‚Ä¶), ont √©t√© d√©velopp√©es. C‚Äôest le cas de [Terraform](https://www.terraform.io/). 
Cependant, n‚Äôimporte quelle outils demande de respecter de bonne pratiques. Conna√Ætre et r√©pandre les bonnes pratiques de l'utilisation de ce genre d‚Äôoutil permet une meilleure maintenance de ces applications et de corriger de nombreux probl√®mes, qu‚Äôils s'agissent de probl√®mes de lisibilit√©, de s√©curit√©, de performance ou autre. 

## II. Probl√©matique

Cependant, ce n‚Äôest pas parce qu‚Äôon connait une bonne pratique qu‚Äôelle est correctement appliqu√©e. Pour autant qu‚Äôon sache, aussi incroyable soit les outils comme Terraform, il pourrait √™tre mal utilis√© en pratique. Mais comment v√©rifie-t-on que si c‚Äôest le cas ?  Pour certifier qu‚Äôun projet est de bonne qualit√©, il faut s‚Äôassurer qu‚Äôil respecte les bonnes pratiques autant que possible. Il faut donc les mesurer. Mais comment les mesurer ? Est-t-il ne serait-ce que possible de les mesurer ?

Ainsi, lors de ce projet nous chercherons √† r√©pondre √† toute ces question que nous reformulons sous la forme suivante :

**Quelles bonnes pratiques de Terraform sont v√©rifiables ?**

1. Comment d√©finir une bonne pratique en Terraform ?
2. Quelles pratiques sont encourag√©es en Terraform ?
3. Est-ce que Terraform est toujours bien utilis√© en pratique ?

## III. Hypoth√®ses, Collecte d‚Äôinformations & Exp√©riences

Notre projet se concentre sur la notion de bonne pratique. Avant toute chose, il nous faut d√©finir ce qu‚Äôest une bonne pratique.  Cette d√©finition n‚Äôest pas une d√©finition unique, mais c‚Äôest √† partir de cette d√©finition que va √©voluer le projet par la suite. 
Nous d√©finirons une d√©finition en v√©rifiant les point suivant :
- Une bonne pratique est justifi√©e.
- Une bonne pratique est non essentielle au fonctionnement de Terraform.
- Une bonne pratique est valide pour les versions r√©centes de Terraform.
- Une bonne pratique est appuy√©e par des exemples (optionnel).
- Une bonne pratique est mesurable (optionnel).

A partir de cette d√©finition, nous pouvons rechercher et lister des bonnes pratiques en renseignant une description, une source, une explication, un potentiel exemple et une estimation de mesurabilit√©. Enfin, nous regroupons ces pratiques √† l‚Äôaide de tags qui permettent de cerner certaines cat√©gories de pratique (s√©curit√©, lisibilit√©, ‚Ä¶).
Vous trouverez l‚Äôensemble des pratiques r√©pertori√©es dans ce tableau.

Maintenant que nous avons des pratiques, il nous faut estimer si elles sont bien utilis√©es en pratique.

Pour ce faire il nous faut des **projet de r√©f√©rence √† analyser**, qui puissent repr√©senter ‚Äúla pratique‚Äù √©nonc√©e dans la question. Ensuite, il nous faut des **outils pour analyser des pratique dans un projet*. Enfin, nous pourrons lancer une analyse des dits projet afin d‚Äôestimer si telle ou telle bonne pratique est correctement employ√©e.

#### Projets de r√©f√©rence

Avec ces projets, nous devons repr√©senter une norme. Il ne faut pas que ce soit des projets r√©alis√©s par un d√©veloppeur solitaire en autodidacte ou par une classe d'√©tudiants. 
En ce sens, nous d√©finirons que la s√©lection des projets sera influenc√©e par la **taille** du projet, sa **popularit√©**, la taille et l‚Äôexp√©rience de l‚Äô**√©quipe** de d√©veloppement, la r√©gularit√© des **mises √† jour** et la densit√© de la partie consacr√©e √† **Terraform**.

En ce sens, nous avons s√©lectionn√© une petite quantit√© de code de confiance r√©colt√© √† la main pour plus de certitude. 

| Nom | Taille | Popularit√© | Cr√©ation | R√©gularit√© | Contributeurs |
| :-------- | :------: | :---------------: | :-----------: | :-------------: | :-------------------: |
| [StubbornJava](https://github.com/StubbornJava/StubbornJava) | 1214 ko | 218 stars | Dec. 2016| 361 commits | 4 |
| [Atlantis](https://github.com/runatlantis/atlantis) | 43 567 ko | 4.4k stars | Mai 2017| 2014 commits | 206 |
| [Docker Android](https://github.com/budtmo/docker-android) | 242 262 ko | 4.2k stars | Dec. 2016 | 541 commits | 38 |
| [DetectionLab](https://github.com/clong/DetectionLab) | 198 188 ko | 3.3k stars | Dec. 2017 | 541 commits | 6 |
| [StreamAlert](https://github.com/airbnb/streamalert) | 44 411 ko | 2.7k stars | Jan. 2017 | 1900 commits | 30 |

Le probl√®me ici est la quantit√© de projets. Cependant, il est difficile de rechercher des projets de confiance avec [GitHub](https://github.com/). Peu de filtres, d√©tection de code Terraform difficile et limite d‚Äôutilisation, le service a beaucoup de limites emp√™chant une bonne s√©lection de projets pertinents.
Il nous faut donc de meilleures m√©thodes de recherche. Pour cela nous pourrions utiliser des technologies comme [CodeDJ](https://2021.ecoop.org/details/ecoop-2021-ecoop-research-papers/7/CodeDJ-Reproducible-Queries-over-Large-Scale-Software-Repositories) qui offrent un DSL permettant des recherches plus pertinentes.

Cependant, les recherches concernant l‚Äôutilisation de CodeDJ n‚Äôont √† ce jour pas port√© leur fruit, leur base de donn√©es √©tant priv√©e, et reste √† l‚Äô√©tat de piste de recherche.

#### Outils d‚Äôanalyse

Pour savoir si Terraform est bien utilis√© en pratique, il faut mesurer cela gr√¢ce √† des outils. De ce fait, nous s√©lectionnons des outils en proc√©dant par recherches avec Github. Notre recherche  se fait en fonction de plusieurs crit√®res : leur popularit√©, s‚Äôils sont Open Source ou non et enfin la gratuit√© de l‚Äôoutil. 
Au terme de cette recherche nous retenons 6 outils : TFLint, Checkov, TFSec, Terrascan, Regula, Snyk IAC, tous traitant de domaines diff√©rents (analyse syntaxique, s√©curit√©, etc.). Cependant, il nous para√Æt important de v√©rifier le nombre de r√®gles que v√©rifient ces outils et le nombre de technologies auxquelles ils s‚Äôappliquent : ainsi nous voyons que Checkov est le projet le plus flexible avec un total de 1600 r√®gles trait√©es et une couverture large des technologies. TFSec est lui aussi assez flexible. En revanche, en appliquant de nouveaux filtres,  nous constatons qu‚Äôun bon nombre de projets ont une complexit√© non n√©gligeable en raison du langage qu‚Äôils utilisent (Rego, Go) et il est donc complexe d‚Äô√©crire une r√®gle personnalis√©e dans ces langages. Apr√®s quelques essais, nous nous apercevons que mettre en place une r√®gle en Checkov, m√™me avec un langage facile √† prendre en main comme Python, reste compliqu√©. Au mieux, nous finirons par cr√©er une r√®gle qui utiliserait les r√®gle d√©j√† d√©finie par le logiciel et ce n‚Äôest pas notre objectif. C‚Äôest pourquoi une piste d‚Äôexploration peut √™tre d‚Äôessayer de mettre en place une r√®gle avec TFLint malgr√© qu‚Äôil faille l‚Äô√©crire en Go. 

Par la suite, nous allons nous concentrer sur l‚Äôutilisation de Checkov.

#### Analyse

Nous pouvons maintenant analyser les projets avec Checkov :

| Projet | Taux de succ√®s |
| :--------- | :-----------------------: |
|  StubbornJava	| 13% üü• |
|  Atlantis		| 50% üüß |
|  Docker		| 76% üü® |
|  DetectionLab	| 48% üüß | 
|  StreamAlert		| 94% üü© |

Le probl√®me ici c‚Äôest que √ßa nous ne nous donne aucune preuve que cette analyse refl√®te une bonne ou mauvaise utilisation de bonne pratique. En effet, rien nous dit que les v√©rifications effectu√©es par Checkov v√©rifient une pratique qui respecte notre d√©finition d‚Äôune bonne pratique.

La question est : Comment pouvons nous utiliser checkov pour prouver une bonne pratique ?
Dans un premier temps, nous allons s√©lectionner un petit √©chantillon de bonne pratique simple afin de v√©rifier que l‚Äôanalyse est possible avant de l‚Äô√©tendre au reste de la s√©lection.

Ainsi, nous nous concentrerons sur les pratique, acc√®s s√©curis√©, suivante :
- Ne jamais √©crire des identifiants en clair dans un fichier de configuration de Terraform.
- Ne jamais partager le fichier .tfstate sur le repository.
- Ne jamais divulguer de secrets en clair dans les sorties d'une configuration Terraform.

Il faut maintenant nous demander comment les v√©rifier dans un projet.

Pour que l‚Äôutilisation de chekov soit pertinent pour v√©rifier ces pratiques, il nous faut s√©lectionner des r√®gle d√©finie par la technologie qui sont associable √† nos bonne pratique. Ainsi, nous effecturons les v√©rification suivante : CKV_AWS_41, CKV_AWS_45, CKV_AWS_46, CKV_AWS_58, CKV_AWS_149	, CKV_AZURE_41, CKV_BCW_1, CKV_GIT_4, CKV_LIN_1, 
CKV_OCI_1, CKV_OPENSTACK_1, CKV_PAN_1. Toutes ont √©t√© s√©lectionn√©es manuellement pour v√©rifier qu'elles sont bien associ√©es √† nos bonnes pratiques.

Ainsi, nous pouvons utiliser la commande suivante sur les projets :
``` 
checkov -d <directory> --compact --framework terraform --check CKV_AWS_41,CKV_AWS_45,CKV_AWS_46,CKV_AWS_58,CKV_AWS_149,CKV_AZURE_41,CKV_BCW_1,CKV_GIT_4,CKV_LIN_1,CKV_OCI_1,CKV_OPENSTACK_1,CKV_PAN_1
```
 
De cette mani√®re, nous obtenons les r√©sultat suivant :

| Projet | Taux de succ√®s |
| :--------- | :-----------------------: |
|  StubbornJava	| 100% üü©|
|  Atlantis		| 100% üü©|
|  Docker		| 100% üü©|
|  DetectionLab	| 100% üü©|
|  StreamAlert		| 100% üü©|

Nous observons un total respect des r√®gles en question. De par ce r√©sultat, nous pouvons affirmer que les bonnes pratiques s√©lectionn√©es sont en effet bien respect√©es. Cependant, cette affirmation est fond√©e sur peu de projets. Afin de confirmer cette affirmation, il est n√©cessaire de trouver plus de projets pertinents √† analyser.

A d√©faut de pouvoir utiliser CodeDJ, nous retournons sur une recherche GitHub manuelle. Cette fois-ci en recherchant avec des mots cl√©s que l‚Äôon peut retrouver dans des fichiers Terraform. Cependant, bien que cela nous permet de conna√Ætre des projets ayant des fichiers Terraform, cela ne nous permet pas de faire des filtre sur ces projets. Afin de combler ce manque, nous mettons en place une m√©thodologie de recherche et des script permettant leur ex√©cution. 

#### Recherche de projet - M√©thodologie

Afin d‚Äôeffectuer une recherche des projets GitHub contenant au moins un fichier Terraform, nous avons tent√© une premi√®re approche √† base de requ√™tes √† l'API de GitHub:

- `extension:tf language:hcl` (2 096 750 fichiers trouv√©s)
=> Trop de fichiers par projet, le parcours est par cons√©quent trop long
- `terraform extension:tf` (505 379 fichiers trouv√©s)
=> Trop de fichiers par projet, le parcours est par cons√©quent trop long 
=> Certains fichiers invalides indiquent des r√©sultats peu fiables
- terraform extension:tf language:hcl 		(504 803 fichiers trouv√©s)
=> Trop de fichiers par projet, le parcours est par cons√©quent trop long 
- `terraform extension:tf` (126 222 fichiers trouv√©s)
=> Trop de fichiers par projet, le parcours est par cons√©quent trop long
=> Certains fichiers invalides indiquent des r√©sultats peu fiables
- `required_providers extension:tf language:hcl` (126 219 fichiers trouv√©s) 
=> Requ√™te OK ‚úÖ
Cette derni√®re requ√™te fonctionne car l‚Äôargument `required_providers` n'est d√©clar√© qu'une seule fois par projet Terraform (d√©claration des d√©pendances).
√âvidemment, il est toujours possible de d√©tecter plusieurs fichiers r√©pondant √† ces crit√®res dans un projet. Cependant, cela semble √™tre grandement limit√© au vu du nombre de fichiers trouv√©s lors de chaque requ√™te. 
Malheureusement, l'API de GitHub impose de nombreuses limites d'utilisation. Elle limite notamment le nombre de requ√™tes de recherche √† 30 requ√™tes/min, le nombre de r√©sultats par page √† 100, ainsi que le nombre de r√©sultats accessibles par requ√™te √† 1000 (m√™me lorsque l‚Äôon utilise la pagination).
Il est donc n√©cessaire de trouver une strat√©gie afin de r√©cup√©rer le maximum de fichiers (et donc de projets associ√©s). Pour cela, nous avons utilis√© l'argument size dans la requ√™te qui permet d'indiquer la taille des fichiers (en octets) que nous souhaitons trouver.

Premi√®re strat√©gie : Envoyer une requ√™te par taille de 0 √† 203 000 octets, cette grande taille n‚Äô√©tant pas arbitraire mais correspond au plus grand fichier identifi√©.
Exemple : `required_providers extension:tf language:hcl size:1`,
`required_providers extension:tf language:hcl size:2`, ‚Ä¶

Le parcours trop long et fastidieux (203 000 requ√™tes potentielles).
En effet, nous avons calcul√© qu'il faudrait 4.7 jours de calcul pour 203 000 / 30 = 6767 secondes = 112 heures = 4.7 jours

Deuxi√®me strat√©gie : Envoyer une requ√™te par intervalle de taille entre 0 et 203 000 octets, avec un pas de 50 octets.
Exemple : `required_providers extension:tf language:hcl size:0..49`,
`required_providers extension:tf language:hcl size:50..99`, ...

Cette strat√©gie de requ√™te nous semble d√©j√† plus appropri√©e, limitant le nombre de requ√™tes possibles.
N√©anmoins, elle n√©cessite d'identifier un intervalle limit√©, √† la fois calculable en temps et efficient, afin de r√©cup√©rer le maximum de projets.

Nous allons donc essayer d‚Äôaffiner cet intervalle, ci-dessous un graphe r√©sultant d‚Äôun pas plus petit que pr√©c√©demment: 10 octets.

Nous pouvons ais√©ment remarquer une zone plus dense que les autres de 60 √† 3780 octets. Cet intervalle regroupe 95% des fichiers Terraform trouv√©s par GitHub. Pour cette raison, nous allons nous concentrer sur cet intervalle avec un pas de 5 octets pour r√©cup√©rer le maximum de fichiers Terraform (et donc de projets √† analyser) en un minimum de temps. Une fois l‚Äôanalyse termin√©e, nous constatons que nous avons identifi√© un total de 92 repositories GitHub contenant au moins un fichier Terraform. 

## V. R√©sultats et Conclusion

Une fois que nous avons r√©cup√©r√© la liste des repositories, nous utilisons un second script pour analyser chaque repository avec Checkov :

| Nombre de projet | Taux de succ√®s moyen | Projets ayant 100% de succ√®s |
| :--------------------------- | :-----------------------------------: | :----------------------------------------------: |
| 92                            |	88,04%                          | 	80,43%                             |

A premi√®re vue, Terraform semble √™tre bien utilis√© en pratique. Du moins, cette affirmation est bas√©e sur les bonnes pratiques que nous avons nous m√™mes s√©lectionn√©es. Afin de g√©n√©raliser cette affirmation, il serait n√©cessaire de recommencer une proc√©dure identique, adapt√© pour l‚Äôint√©gralit√© des bonnes pratiques, c.a.d:
S√©lection de l‚Äôoutils le plus adapt√© (Checkov √©tant le plus adapt√© pour les pratiques li√© √† la s√©curit√© par exemple)
S√©lection des r√®gles de l'outil associ√© aux bonnes pratiques retenues (voir en cr√©er si n√©cessaire).
Lancement de l‚Äôoutil avec les r√®gles s√©lectionn√©es sur les projets pr√©c√©demment s√©lectionn√©s.
Analyse des r√©sultats.

Cela repr√©sente un travail long et fastidieux, surtout si l‚Äôon prend en compte que certaines bonnes pratiques sont plus accessoires que d‚Äôautres: facilit√© de maintenance aupr√®s des d√©veloppeurs contre d√©faut majeur ou faille de s√©curit√© en cas de n√©gligence.

Si l‚Äôon se restreint √† notre s√©lection, nous pouvons affirmer au vu des r√©sultats que Terraform est bien utilis√© en pratique.

## VI. References

1. ref1
1. ref2
